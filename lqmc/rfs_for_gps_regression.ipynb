{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coupled RFFs for GPs notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.stats import ortho_group\n",
    "from scipy.stats.distributions import chi2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy.stats.distributions import chi2\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and stuff\n",
    "\n",
    "dataset = 'wine'\n",
    "test_frac = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/path/to/dataset/dir')         #path to dataset directory\n",
    "\n",
    "if dataset == 'abalone':\n",
    "    abalone_data = pd.read_csv('abalone.data', delimiter=\",\")\n",
    "    all_data = np.asarray(abalone_data)\n",
    "    all_data = np.hstack((np.asarray([all_data[:,8]]).T, all_data[:,1:7]))\n",
    "    all_data = np.asarray(all_data,dtype=float)\n",
    "\n",
    "    #noise = 0.2\n",
    "    noise = 0.8\n",
    "    lengthscale = 8\n",
    "    coefficient = 1\n",
    "\n",
    "if dataset == 'wine':\n",
    "    wine_data = pd.read_csv('wine.data', delimiter=\",\")\n",
    "    all_data = np.asarray(wine_data)\n",
    "\n",
    "    #noise = 0.24\n",
    "    noise = 1\n",
    "    lengthscale = 6.5\n",
    "    coefficient = 1\n",
    "\n",
    "if dataset == 'air':\n",
    "    air_data = pd.read_csv('AirQualityUCI.csv', delimiter=\";\")\n",
    "    all_data = np.asarray(air_data)[:9357,2:15]\n",
    "    all_data = all_data[:400]\n",
    "    for row in range(np.shape(all_data)[0]):\n",
    "        for column in range(np.shape(all_data)[1]):\n",
    "            all_data[row, column] = float(str(all_data[row,column]).replace(',', '.'))\n",
    "    new_all_data = []\n",
    "    for data in all_data:\n",
    "        if data[0] != -200.0:\n",
    "            new_all_data.append(data)\n",
    "    all_data = np.asarray(new_all_data, dtype = float)\n",
    "\n",
    "if dataset == 'housing':\n",
    "    housing_data = pd.read_csv('HousingData.csv', delimiter=\",\")\n",
    "    all_data = np.asarray(housing_data)\n",
    "    all_data = np.hstack((np.asarray([all_data[:,13]]).T, all_data[:,:13]))\n",
    "    new_all_data = []\n",
    "    for data in all_data:\n",
    "        if math.isnan(np.mean(data)) == False:\n",
    "            new_all_data.append(data)\n",
    "    all_data = np.asarray(new_all_data)\n",
    "\n",
    "    #noise = 0.11\n",
    "    noise = 1\n",
    "    lengthscale = 5\n",
    "    coefficient = 1.3\n",
    "\n",
    "if dataset == 'parkinsons':\n",
    "    parkinsons_data = pd.read_csv('parkinsons_updrs.data', delimiter=\",\")\n",
    "    all_data = np.asarray(parkinsons_data)[:,5:]        #doing the 'total' task\n",
    "\n",
    "    #noise = 0.35\n",
    "    noise = 1\n",
    "    lengthscale = 10\n",
    "    coefficient = 0.5\n",
    "\n",
    "if dataset == 'cpu':\n",
    "    machine_data = pd.read_csv('machine.data', delimiter=\",\")\n",
    "    all_data = np.asarray(machine_data)[:,2:]\n",
    "    all_data = np.hstack((np.asarray([all_data[:,7]]).T, all_data[:,:7]))\n",
    "    all_data = np.asarray(all_data, dtype = float)\n",
    "\n",
    "    noise = 1\n",
    "    lengthscale = 4\n",
    "    coefficient = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and preprocess data\n",
    "\n",
    "indices = [i for i in range(len(all_data))]\n",
    "np.random.shuffle(indices)\n",
    "all_data = all_data[[indices]][0]\n",
    "\n",
    "all_data = all_data[:500]\n",
    "\n",
    "train = all_data[:int(len(all_data) * (1 - test_frac))]\n",
    "test = all_data[ int(len(all_data) * (1 - test_frac)):]\n",
    "\n",
    "\n",
    "\n",
    "y_data = train[:,0]\n",
    "x_data = train[:,1:]\n",
    "\n",
    "x_data_mean = np.mean(x_data,axis = 0)\n",
    "x_data_std = np.std(x_data, axis = 0)\n",
    "x_data -= x_data_mean\n",
    "x_data *= (1 / x_data_std)\n",
    "y_mean = np.mean(y_data)\n",
    "y_data /= y_mean\n",
    "x_pred = test[:,1:]\n",
    "x_pred -= x_data_mean\n",
    "x_pred *= (1 / x_data_std)\n",
    "y_pred = test[:,0]\n",
    "y_pred /= y_mean\n",
    "\n",
    "d = np.shape(x_data)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the respective orientations of the weights vectors\n",
    "m=2     #control no. samples\n",
    "\n",
    "basis = np.eye(d)[:m]                   #orthogonal basis\n",
    "#basis = np.vstack((basis,-basis))          #antiparallel directions (can include optionally)\n",
    "nb_vecs = len(basis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_features:\n",
    "    \n",
    "    def get_iid_rffs(xs, nb_features, lengthscale): \n",
    "    # get iid rffs\n",
    "        \n",
    "        for feature in range(nb_features):\n",
    "            w = np.random.normal(size = (len(basis),d))\n",
    "            holder = np.matmul(w,np.transpose(xs / lengthscale))\n",
    "            cs_holder = np.concatenate([np.cos(holder),np.sin(holder)],axis=0)\n",
    "            if feature == 0:\n",
    "                rfs = cs_holder\n",
    "            else:\n",
    "                rfs = np.vstack((cs_holder,rfs))\n",
    "        rfs = rfs.T / np.sqrt(nb_features * nb_vecs)\n",
    "        return rfs\n",
    "\n",
    "    def get_orth_rffs(xs, ws, lengthscale): \n",
    "    #get orthogonal rffs (takes frequency vector norms as input)\n",
    "        \n",
    "        nb_features = len(ws)\n",
    "        for feature, w in enumerate(ws):\n",
    "            w = np.matmul(np.diag(w),basis)\n",
    "            rotation = ortho_group.rvs(d)      #get the rotation matrix to apply to all the data\n",
    "            holder = np.matmul(w,np.matmul(rotation,np.transpose(xs / lengthscale)))\n",
    "            cs_holder = np.concatenate([np.cos(holder),np.sin(holder)],axis=0)\n",
    "            if feature == 0:\n",
    "                rfs = cs_holder\n",
    "            else:\n",
    "                rfs = np.concatenate((np.reshape(rfs, [feature,2*nb_vecs,len(xs)]),np.reshape(cs_holder, [1,2*nb_vecs,len(xs)])),axis=0)\n",
    "        rfs = np.transpose(np.reshape(rfs, [nb_features*2*nb_vecs,len(xs)])) / np.sqrt(nb_features * nb_vecs)\n",
    "        return rfs\n",
    "    \n",
    "    def get_approx_covariance(xs, coupling, nb_features, coefficient, lengthscale, noise = None):\n",
    "    #construct approx Gram matrix\n",
    "\n",
    "        if coupling == 'iid':        \n",
    "            phi = random_features.get_iid_rffs(xs, nb_features, lengthscale)\n",
    "        elif coupling == 'orth':\n",
    "            ws = np.sqrt(np.random.chisquare(d,size=(nb_features,len(basis))))\n",
    "            phi = random_features.get_orth_rffs(xs, ws, lengthscale)\n",
    "        elif coupling == 'coupled':\n",
    "            w1 = np.random.random(size=(nb_features,int(len(basis)/2)))\n",
    "            ws = np.hstack((w1,1-w1))\n",
    "            if len(basis)%2 == 1:\n",
    "                ws = np.asarray([np.hstack((ws,np.asarray([np.random.random(nb_features)]).T))])[0]\n",
    "                \n",
    "            ws = np.sqrt(chi2.ppf(ws, df=d))\n",
    "            phi = random_features.get_orth_rffs(xs, ws, lengthscale)\n",
    "        else:\n",
    "            raise Exception('Coupling not recognised')\n",
    "\n",
    "        K_approx = (phi @ phi.T) * coefficient\n",
    "        if noise is not None:\n",
    "            K_approx += noise**2 * np.eye(np.shape(x_data)[0])\n",
    "\n",
    "        return K_approx\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for GPs stuff\n",
    "\n",
    "def covariance(x,x_prime,lengthscale,coefficient,noise):\n",
    "   #get exact covariance matrix for Gaussian kernel\n",
    "\n",
    "   diff_mat = x[:,None,:]-x_prime[None,:,:]\n",
    "   cov = coefficient * np.exp(-np.sum(diff_mat**2/(2 * lengthscale**2),axis=2))\n",
    "   if noise is not None:\n",
    "       cov = cov + noise ** 2 * np.eye(cov.shape[0])\n",
    "   return cov\n",
    "\n",
    "def get_gp_posterior_mean(Kdd,Kpd,y_data):\n",
    "   #compute posterior mean for datapoints given kernel matrices and observed data\n",
    "   return Kpd @ np.linalg.solve(Kdd, y_data)\n",
    "\n",
    "def get_log_likelihood(K, y):\n",
    "    #Takes Gram matrix and input data, returns data log marginal likelihood for corresponding DP\n",
    "    n = len(y)\n",
    "    L = np.linalg.cholesky(K)\n",
    "    L_diag = [L[i,i] for i in range(len(L))]\n",
    "    alpha = np.linalg.solve(L.T, np.linalg.solve(L,y))\n",
    "    log_likelihood = -0.5 * np.dot(y,alpha) - np.sum(np.log(L_diag)) - n/2 * np.log(2 * np.pi)\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def do_regression_test(x_data, x_pred, coupling, nb_features, lengthscale, coefficient, noise, y_data, y_pred):\n",
    "   #try regression and see what error is\n",
    "   both_x = np.concatenate((x_data,x_pred))\n",
    "   big_K = random_features.get_approx_covariance(both_x, coupling, nb_features, coefficient, lengthscale, None)\n",
    "   Kdd = big_K[:len(x_data),:len(x_data)]\n",
    "   if noise is not None:\n",
    "      Kdd += np.eye(np.shape(x_data)[0]) * noise**2\n",
    "   Kpd = big_K[len(x_data):, :len(x_data)]\n",
    "   return np.mean((Kpd @ np.linalg.solve(Kdd, y_data) - y_pred)**2) / np.mean(y_pred**2)\n",
    "\n",
    "\n",
    "def get_gp_posterior_mean_and_cov(Kdd, Kpd, Kpp, y_data):\n",
    "   posterior_mean = Kpd @ np.linalg.solve(Kdd, y_data)\n",
    "   posterior_cov = Kpp - Kpd @ np.linalg.solve(Kdd, Kpd.T)\n",
    "   return posterior_mean, posterior_cov\n",
    "\n",
    "def get_approx_Ks(x_data, x_pred, coupling, nb_features, lengthscale, coefficient, noise, y_data):\n",
    "   both_x = np.concatenate((x_data,x_pred))\n",
    "   big_K = random_features.get_approx_covariance(both_x, coupling, nb_features, coefficient, lengthscale, None)\n",
    "   Kdd = big_K[:len(x_data),:len(x_data)]\n",
    "   if noise is not None:\n",
    "      Kdd += np.eye(np.shape(x_data)[0]) * noise**2\n",
    "   Kpd = big_K[len(x_data):, :len(x_data)]\n",
    "   Kpp = big_K[len(x_data):,len(x_data):]\n",
    "   return Kdd, Kpd, Kpp\n",
    "\n",
    "def get_KL_div(exact_mean, approx_mean, exact_cov, approx_cov):\n",
    "   KL_d = np.trace(np.linalg.solve(approx_cov, exact_cov)) + (approx_mean - exact_mean).T @ np.linalg.solve(approx_cov, (approx_mean - exact_mean)) - len(exact_mean) + np.log( np.abs(np.linalg.det(approx_cov))) - np.log(np.abs(np.linalg.det(exact_cov))) \n",
    "   return KL_d\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the exact Gram matrices and posterior mean\n",
    "\n",
    "Kdd_exact = covariance(x_data, x_data, lengthscale, coefficient, noise)\n",
    "Kpd_exact = covariance(x_pred, x_data, lengthscale, coefficient, None)\n",
    "Kpp_exact  = covariance(x_pred, x_pred, lengthscale, coefficient, None)\n",
    "\n",
    "exact_mean, exact_cov = get_gp_posterior_mean_and_cov(Kdd_exact, Kpd_exact, Kpp_exact, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "couplings = ['iid','orth','coupled']\n",
    "nb_features = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for comparing log likelihoods. Not sure this is a very good metric.\n",
    "\n",
    "if False:\n",
    "    for coupling in couplings:\n",
    "        nb_tests = 1000\n",
    "        log = []\n",
    "        for test in tqdm(range(nb_tests)):\n",
    "            Kdd_approx = random_features.get_approx_covariance(x_data, coupling, nb_features, coefficient, lengthscale, noise)\n",
    "            log.append(get_log_likelihood(Kdd_approx, y_data))\n",
    "        print(str(np.mean(log)) + ' =- ' + str(np.std(log) / np.sqrt(nb_tests)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 497.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.613303048392133 =- 0.03251852031737341\n",
      "0.0018638840345447344 =- 3.1529088728713635e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 336.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.525878300750357 =- 0.032451201202523844\n",
      "0.0017565280227200186 =- 2.7742544562127172e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 272.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.443231290594891 =- 0.026905900395360963\n",
      "0.0017998305621720948 =- 3.0162315071598887e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#for comparing KL divergence between true and approx dist\n",
    "if True:\n",
    "    for coupling in couplings:\n",
    "        nb_tests = 1000\n",
    "        log1 = []\n",
    "        log2 = []\n",
    "        for test in tqdm(range(nb_tests)):\n",
    "            Kdd_approx, Kpd_approx, Kpp_approx = get_approx_Ks(x_data, x_pred, coupling, nb_features, lengthscale, coefficient, noise, y_data)\n",
    "            approx_mean, approx_cov = get_gp_posterior_mean_and_cov(Kdd_approx, Kpd_approx, Kpp_approx, y_data)\n",
    "            log1.append(get_KL_div(exact_mean,approx_mean,exact_cov,approx_cov))\n",
    "            log2.append(np.sum((approx_mean - exact_mean)**2) / np.sum(exact_mean**2))\n",
    "        print(str(np.mean(log1)) + ' =- ' + str(np.std(log1) / np.sqrt(nb_tests)))\n",
    "        print(str(np.mean(log2)) + ' =- ' + str(np.std(log2) / np.sqrt(nb_tests)))\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 951.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004613561730956952 =- 6.426689734886874e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 408.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004250278564800378 =- 5.4904567732245176e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 401.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003950719587653793 =- 4.4856627950755134e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#for comparing Gram matrix approximation directly\n",
    "for coupling in couplings:\n",
    "    nb_tests = 1000\n",
    "    log = []\n",
    "    for test in tqdm(range(nb_tests)):\n",
    "        log.append(np.sum((Kdd_exact - random_features.get_approx_covariance(x_data, coupling, nb_features, coefficient, lengthscale, noise))**2) / np.sum(Kdd_exact**2))\n",
    "    print(str(np.mean(log)) + ' =- ' + str(np.std(log) / np.sqrt(nb_tests)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 947.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01552025082039408 =- 3.9699210770761034e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:27<00:00, 365.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015369707103572886 =- 3.820772832770254e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:25<00:00, 388.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01542612570228066 =- 3.805291658257977e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#for comparing predictive accuracy. Probably need to average over data splits\n",
    "\n",
    "for coupling in couplings:\n",
    "    nb_tests = 10000\n",
    "    log = []\n",
    "    for test in tqdm(range(nb_tests)):\n",
    "        error = do_regression_test(x_data, x_pred, coupling, nb_features, lengthscale, coefficient, noise, y_data, y_pred)\n",
    "        log.append(error)\n",
    "    print(str(np.mean(log)) + ' =- ' + str(np.std(log) / np.sqrt(nb_tests)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c3d621010972cfbd796373eb90e225d08b61afb98c052236727878caeec28ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
